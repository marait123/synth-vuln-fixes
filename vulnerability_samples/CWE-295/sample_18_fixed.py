import aiohttp
import ssl
import asyncio
import logging
from dataclasses import dataclass
from typing import List, Dict

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class SiteConfig:
    url: str
    keywords: List[str]

class DataProcessor:
    @staticmethod
    def process_html(html: str, keywords: List[str]) -> Dict[str, int]:
        return {keyword: html.lower().count(keyword.lower()) for keyword in keywords}

class Reporter:
    @staticmethod
    def generate_report(site: str, keyword_counts: Dict[str, int]) -> str:
        report = f"Report for {site}:\n"
        for keyword, count in keyword_counts.items():
            report += f"- '{keyword}' found {count} times\n"
        return report

async def fetch(session, url):
    ssl_context = ssl.create_default_context()
    try:
        async with session.get(url, ssl=ssl_context) as response:
            return await response.text()
    except aiohttp.ClientError as e:
        logger.error(f"Error fetching {url}: {e}")
        return ""

async def process_site(session, config: SiteConfig):
    html = await fetch(session, config.url)
    if html:
        keyword_counts = DataProcessor.process_html(html, config.keywords)
        report = Reporter.generate_report(config.url, keyword_counts)
        logger.info(report)
    else:
        logger.warning(f"No data fetched for {config.url}")

async def main():
    sites = [
        SiteConfig("https://example.com", ["example", "domain"]),
        SiteConfig("https://python.org", ["python", "programming"]),
    ]

    async with aiohttp.ClientSession() as session:
        tasks = [process_site(session, site) for site in sites]
        await asyncio.gather(*tasks)

if __name__ == "__main__":
    asyncio.run(main())